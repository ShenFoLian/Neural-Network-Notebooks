{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d7b118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38073a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3ffbfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/shakespeare.txt','r',encoding='utf8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2fe3ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad83849c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bud buriest thy content,\\n  And tender churl mak'st waste in niggarding:\\n    Pity the world, or else this glutton be,\\n    To eat the world's due, by the grave and thee.\\n\\n\\n                     2\\n  When forty winters shall besiege thy brow,\\n  And dig deep trenches in thy beauty's field,\\n  Thy youth's proud livery so gazed on now,\\n  Will be a tattered weed of small worth held:  \\n  Then being asked, where all thy beauty lies,\\n  Where all the treasure of thy lusty days;\\n  To say within thine own deep su\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Raw string\n",
    "text[:1000]     # \\n stands for a new line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b37b9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bud buriest thy content,\n",
      "  And tender churl mak'st waste in niggarding:\n",
      "    Pity the world, or else this glutton be,\n",
      "    To eat the world's due, by the grave and thee.\n",
      "\n",
      "\n",
      "                     2\n",
      "  When forty winters shall besiege thy brow,\n",
      "  And dig deep trenches in thy beauty's field,\n",
      "  Thy youth's proud livery so gazed on now,\n",
      "  Will be a tattered weed of small worth held:  \n",
      "  Then being asked, where all thy beauty lies,\n",
      "  Where all the treasure of thy lusty days;\n",
      "  To say within thine own deep su\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccba7e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5445609"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f243c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_characters = set(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c60daca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '>',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " ']',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '|',\n",
       " '}'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d93ab645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "262d7f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'r')\n",
      "(1, 'C')\n",
      "(2, 'Z')\n",
      "(3, '3')\n",
      "(4, 'l')\n",
      "(5, 'U')\n",
      "(6, 'M')\n",
      "(7, 'q')\n",
      "(8, 'E')\n",
      "(9, 'T')\n",
      "(10, ',')\n",
      "(11, ';')\n",
      "(12, '>')\n",
      "(13, 't')\n",
      "(14, 'k')\n",
      "(15, '6')\n",
      "(16, 'L')\n",
      "(17, 'c')\n",
      "(18, 'R')\n",
      "(19, 'f')\n",
      "(20, 'K')\n",
      "(21, 'g')\n",
      "(22, 'o')\n",
      "(23, '5')\n",
      "(24, 'n')\n",
      "(25, \"'\")\n",
      "(26, 'H')\n",
      "(27, 'b')\n",
      "(28, '}')\n",
      "(29, 'j')\n",
      "(30, 'X')\n",
      "(31, '|')\n",
      "(32, 'G')\n",
      "(33, 'd')\n",
      "(34, '?')\n",
      "(35, 'W')\n",
      "(36, 'm')\n",
      "(37, 'p')\n",
      "(38, 'V')\n",
      "(39, 'B')\n",
      "(40, 'J')\n",
      "(41, '_')\n",
      "(42, '`')\n",
      "(43, 'y')\n",
      "(44, 'P')\n",
      "(45, '&')\n",
      "(46, 'i')\n",
      "(47, 'z')\n",
      "(48, 's')\n",
      "(49, '4')\n",
      "(50, 'N')\n",
      "(51, 'h')\n",
      "(52, ')')\n",
      "(53, 'O')\n",
      "(54, 'v')\n",
      "(55, ' ')\n",
      "(56, 'I')\n",
      "(57, 'Y')\n",
      "(58, 'x')\n",
      "(59, 'Q')\n",
      "(60, '8')\n",
      "(61, '[')\n",
      "(62, 'a')\n",
      "(63, '\"')\n",
      "(64, 'u')\n",
      "(65, 'S')\n",
      "(66, '9')\n",
      "(67, '0')\n",
      "(68, '2')\n",
      "(69, 'e')\n",
      "(70, '\\n')\n",
      "(71, '1')\n",
      "(72, 'D')\n",
      "(73, '7')\n",
      "(74, 'F')\n",
      "(75, 'w')\n",
      "(76, '<')\n",
      "(77, '-')\n",
      "(78, ':')\n",
      "(79, 'A')\n",
      "(80, '(')\n",
      "(81, ']')\n",
      "(82, '.')\n",
      "(83, '!')\n"
     ]
    }
   ],
   "source": [
    "for pair in enumerate(all_characters):\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b15da8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform number values to letters\n",
    "decoder = dict(enumerate(all_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6efb0f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'r',\n",
       " 1: 'C',\n",
       " 2: 'Z',\n",
       " 3: '3',\n",
       " 4: 'l',\n",
       " 5: 'U',\n",
       " 6: 'M',\n",
       " 7: 'q',\n",
       " 8: 'E',\n",
       " 9: 'T',\n",
       " 10: ',',\n",
       " 11: ';',\n",
       " 12: '>',\n",
       " 13: 't',\n",
       " 14: 'k',\n",
       " 15: '6',\n",
       " 16: 'L',\n",
       " 17: 'c',\n",
       " 18: 'R',\n",
       " 19: 'f',\n",
       " 20: 'K',\n",
       " 21: 'g',\n",
       " 22: 'o',\n",
       " 23: '5',\n",
       " 24: 'n',\n",
       " 25: \"'\",\n",
       " 26: 'H',\n",
       " 27: 'b',\n",
       " 28: '}',\n",
       " 29: 'j',\n",
       " 30: 'X',\n",
       " 31: '|',\n",
       " 32: 'G',\n",
       " 33: 'd',\n",
       " 34: '?',\n",
       " 35: 'W',\n",
       " 36: 'm',\n",
       " 37: 'p',\n",
       " 38: 'V',\n",
       " 39: 'B',\n",
       " 40: 'J',\n",
       " 41: '_',\n",
       " 42: '`',\n",
       " 43: 'y',\n",
       " 44: 'P',\n",
       " 45: '&',\n",
       " 46: 'i',\n",
       " 47: 'z',\n",
       " 48: 's',\n",
       " 49: '4',\n",
       " 50: 'N',\n",
       " 51: 'h',\n",
       " 52: ')',\n",
       " 53: 'O',\n",
       " 54: 'v',\n",
       " 55: ' ',\n",
       " 56: 'I',\n",
       " 57: 'Y',\n",
       " 58: 'x',\n",
       " 59: 'Q',\n",
       " 60: '8',\n",
       " 61: '[',\n",
       " 62: 'a',\n",
       " 63: '\"',\n",
       " 64: 'u',\n",
       " 65: 'S',\n",
       " 66: '9',\n",
       " 67: '0',\n",
       " 68: '2',\n",
       " 69: 'e',\n",
       " 70: '\\n',\n",
       " 71: '1',\n",
       " 72: 'D',\n",
       " 73: '7',\n",
       " 74: 'F',\n",
       " 75: 'w',\n",
       " 76: '<',\n",
       " 77: '-',\n",
       " 78: ':',\n",
       " 79: 'A',\n",
       " 80: '(',\n",
       " 81: ']',\n",
       " 82: '.',\n",
       " 83: '!'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09d097dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform letters to number values\n",
    "encoder = {char: ind for ind,char in decoder.items()}      # ind = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3edffe69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r': 0,\n",
       " 'C': 1,\n",
       " 'Z': 2,\n",
       " '3': 3,\n",
       " 'l': 4,\n",
       " 'U': 5,\n",
       " 'M': 6,\n",
       " 'q': 7,\n",
       " 'E': 8,\n",
       " 'T': 9,\n",
       " ',': 10,\n",
       " ';': 11,\n",
       " '>': 12,\n",
       " 't': 13,\n",
       " 'k': 14,\n",
       " '6': 15,\n",
       " 'L': 16,\n",
       " 'c': 17,\n",
       " 'R': 18,\n",
       " 'f': 19,\n",
       " 'K': 20,\n",
       " 'g': 21,\n",
       " 'o': 22,\n",
       " '5': 23,\n",
       " 'n': 24,\n",
       " \"'\": 25,\n",
       " 'H': 26,\n",
       " 'b': 27,\n",
       " '}': 28,\n",
       " 'j': 29,\n",
       " 'X': 30,\n",
       " '|': 31,\n",
       " 'G': 32,\n",
       " 'd': 33,\n",
       " '?': 34,\n",
       " 'W': 35,\n",
       " 'm': 36,\n",
       " 'p': 37,\n",
       " 'V': 38,\n",
       " 'B': 39,\n",
       " 'J': 40,\n",
       " '_': 41,\n",
       " '`': 42,\n",
       " 'y': 43,\n",
       " 'P': 44,\n",
       " '&': 45,\n",
       " 'i': 46,\n",
       " 'z': 47,\n",
       " 's': 48,\n",
       " '4': 49,\n",
       " 'N': 50,\n",
       " 'h': 51,\n",
       " ')': 52,\n",
       " 'O': 53,\n",
       " 'v': 54,\n",
       " ' ': 55,\n",
       " 'I': 56,\n",
       " 'Y': 57,\n",
       " 'x': 58,\n",
       " 'Q': 59,\n",
       " '8': 60,\n",
       " '[': 61,\n",
       " 'a': 62,\n",
       " '\"': 63,\n",
       " 'u': 64,\n",
       " 'S': 65,\n",
       " '9': 66,\n",
       " '0': 67,\n",
       " '2': 68,\n",
       " 'e': 69,\n",
       " '\\n': 70,\n",
       " '1': 71,\n",
       " 'D': 72,\n",
       " '7': 73,\n",
       " 'F': 74,\n",
       " 'w': 75,\n",
       " '<': 76,\n",
       " '-': 77,\n",
       " ':': 78,\n",
       " 'A': 79,\n",
       " '(': 80,\n",
       " ']': 81,\n",
       " '.': 82,\n",
       " '!': 83}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12114eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = np.array([encoder[char] for char in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ac74d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([70, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55,\n",
       "       55, 55, 55, 55, 55, 71, 70, 55, 55, 74,  0, 22, 36, 55, 19, 62, 46,\n",
       "        0, 69, 48, 13, 55, 17,  0, 69, 62, 13, 64,  0, 69, 48, 55, 75, 69,\n",
       "       55, 33, 69, 48, 46,  0, 69, 55, 46, 24, 17,  0, 69, 62, 48, 69, 10,\n",
       "       70, 55, 55,  9, 51, 62, 13, 55, 13, 51, 69,  0, 69, 27, 43, 55, 27,\n",
       "       69, 62, 64, 13, 43, 25, 48, 55,  0, 22, 48, 69, 55, 36, 46, 21, 51,\n",
       "       13, 55, 24, 69, 54, 69,  0, 55, 33, 46, 69, 10, 70, 55, 55, 39, 64,\n",
       "       13, 55, 62, 48, 55, 13, 51, 69, 55,  0, 46, 37, 69,  0, 55, 48, 51,\n",
       "       22, 64,  4, 33, 55, 27, 43, 55, 13, 46, 36, 69, 55, 33, 69, 17, 69,\n",
       "       62, 48, 69, 10, 70, 55, 55, 26, 46, 48, 55, 13, 69, 24, 33, 69,  0,\n",
       "       55, 51, 69, 46,  0, 55, 36, 46, 21, 51, 13, 55, 27, 69, 62,  0, 55,\n",
       "       51, 46, 48, 55, 36, 69, 36, 22,  0, 43, 78, 70, 55, 55, 39, 64, 13,\n",
       "       55, 13, 51, 22, 64, 55, 17, 22, 24, 13,  0, 62, 17, 13, 69, 33, 55,\n",
       "       13, 22, 55, 13, 51, 46, 24, 69, 55, 22, 75, 24, 55, 27,  0, 46, 21,\n",
       "       51, 13, 55, 69, 43, 69, 48, 10, 70, 55, 55, 74, 69, 69, 33, 25, 48,\n",
       "       13, 55, 13, 51, 43, 55,  4, 46, 21, 51, 13, 25, 48, 55, 19,  4, 62,\n",
       "       36, 69, 55, 75, 46, 13, 51, 55, 48, 69,  4, 19, 77, 48, 64, 27, 48,\n",
       "       13, 62, 24, 13, 46, 62,  4, 55, 19, 64, 69,  4, 10, 70, 55, 55,  6,\n",
       "       62, 14, 46, 24, 21, 55, 62, 55, 19, 62, 36, 46, 24, 69, 55, 75, 51,\n",
       "       69,  0, 69, 55, 62, 27, 64, 24, 33, 62, 24, 17, 69, 55,  4, 46, 69,\n",
       "       48, 10, 70, 55, 55,  9, 51, 43, 55, 48, 69,  4, 19, 55, 13, 51, 43,\n",
       "       55, 19, 22, 69, 10, 55, 13, 22, 55, 13, 51, 43, 55, 48, 75, 69, 69,\n",
       "       13, 55, 48, 69,  4, 19, 55, 13, 22, 22, 55, 17,  0, 64, 69,  4, 78,\n",
       "       70, 55, 55,  9, 51, 22, 64, 55, 13, 51, 62, 13, 55, 62,  0, 13, 55,\n",
       "       24, 22, 75, 55, 13, 51, 69, 55, 75, 22,  0,  4, 33, 25, 48, 55, 19,\n",
       "        0, 69, 48, 51, 55, 22,  0, 24, 62, 36, 69, 24, 13, 10, 70, 55, 55,\n",
       "       79, 24, 33, 55, 22, 24,  4, 43, 55, 51, 69,  0, 62,  4, 33, 55, 13,\n",
       "       22, 55, 13, 51, 69, 55, 21, 62, 64, 33, 43, 55, 48, 37,  0, 46, 24,\n",
       "       21, 10, 70, 55, 55, 35, 46, 13, 51, 46, 24, 55, 13, 51, 46, 24, 69,\n",
       "       55, 22, 75, 24, 55, 27, 64])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1186ec20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e470ff4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder[66]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3b498b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(encoded_text,num_uni_chars):\n",
    "    \n",
    "    # encoded_text = batch of encoded text\n",
    "    # num_uni_chars = len(set(text))\n",
    "    \n",
    "    one_hot = np.zeros((encoded_text.size,num_uni_chars))   # Initialize with zeros\n",
    "    \n",
    "    one_hot = one_hot.astype(np.float32)\n",
    "    \n",
    "    # Explanation: https://stackoverflow.com/questions/29831489/convert-array-of-indices-to-1-hot-encoded-numpy-array\n",
    "    one_hot[np.arange(one_hot.shape[0]),encoded_text.flatten()] = 1.0\n",
    "    \n",
    "    one_hot = one_hot.reshape((*encoded_text.shape,num_uni_chars))    # Reshape to match the batch shape\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41084438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test array\n",
    "arr = np.array([1,2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99302abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ae9c18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoder(arr,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d41767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fcedaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28171b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text.reshape((5,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "672ba3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(encoded_text,samp_per_batch=10,seq_len=50):\n",
    "    \n",
    "    # X: Encoded text of length seq_len\n",
    "    # [0, 1, 2]\n",
    "    # [1, 2, 3]\n",
    "    # ...\n",
    "    \n",
    "    # Y: Encoded text shifted by one with same length as X\n",
    "    # [1, 2, 3]\n",
    "    # [2, 3, 4]\n",
    "    # ...\n",
    "    \n",
    "    # How many chars per batch?\n",
    "    char_per_batch = samp_per_batch * seq_len\n",
    "    \n",
    "    # How many batches can we make, given the len of encoded text?\n",
    "    num_batches_avail = int(len(encoded_text)/char_per_batch)\n",
    "    \n",
    "    # Cut off the end of the encoded text, that won't fit evenly into a batch\n",
    "    encoded_text = encoded_text[:num_batches_avail*char_per_batch]\n",
    "    \n",
    "    encoded_text = encoded_text.reshape((samp_per_batch,-1))\n",
    "    \n",
    "    for n in range(0,encoded_text.shape[1],seq_len):\n",
    "        \n",
    "        x = encoded_text[:,n:n+seq_len]\n",
    "        \n",
    "        # Create a zeros array to the same shape as x\n",
    "        y = np.zeros_like(x)\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            y[:,:-1] = x[:,1:]\n",
    "            y[:,-1] = encoded_text[:,n+seq_len]\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            y[:,:-1] = x[:,1:]\n",
    "            y[:,-1] = encoded_text[:,0]\n",
    "            \n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5b2ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = encoded_text[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e90e3fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = np.arange(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "375c86fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4bb0cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_generator = generate_batches(sample_text,samp_per_batch=2,seq_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13a93937",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "872cc9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [10, 11, 12, 13, 14]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59188b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5],\n",
       "       [11, 12, 13, 14, 15]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95000984",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,all_chars,num_hidden=256,num_layers=4,drop_prob=0.5,use_gpu=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.drop_prob = drop_prob\n",
    "        self.num_layers = num_layers\n",
    "        self.num_hidden = num_hidden\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        self.all_chars = all_chars\n",
    "        self.decoder = dict(enumerate(all_chars))\n",
    "        self.encoder = {char:ind for ind,char in decoder.items()}\n",
    "        \n",
    "        self.lstm = nn.LSTM(len(self.all_chars),num_hidden,num_layers,dropout=drop_prob,batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        self.fc_linear = nn.Linear(num_hidden,len(self.all_chars))\n",
    "        \n",
    "    def forward(self,x,hidden):\n",
    "        \n",
    "        lstm_output , hidden = self.lstm(x,hidden)\n",
    "        \n",
    "        drop_output = self.dropout(lstm_output)\n",
    "        \n",
    "        drop_output = drop_output.contiguous().view(-1,self.num_hidden)\n",
    "        \n",
    "        final_out = self.fc_linear(drop_output)\n",
    "        \n",
    "        return final_out,hidden\n",
    "    \n",
    "    def hidden_state(self,batch_size):\n",
    "        \n",
    "        if self.use_gpu:\n",
    "            \n",
    "            hidden = (torch.zeros(self.num_layers,batch_size,self.num_hidden).cuda(),\n",
    "                      torch.zeros(self.num_layers,batch_size,self.num_hidden).cuda())\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            hidden = (torch.zeros(self.num_layers,batch_size,self.num_hidden),\n",
    "                      torch.zeros(self.num_layers,batch_size,self.num_hidden))\n",
    "            \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "266c6c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharModel(all_chars=all_characters,\n",
    "                 num_hidden=512,\n",
    "                 num_layers=3,\n",
    "                 drop_prob=0.5,\n",
    "                 use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c82fd921",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_param = []\n",
    "\n",
    "for p in model.parameters():\n",
    "    total_param.append(int(p.numel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "afc9bcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5470292"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rule of Thumb: Total parameter number is roughly equal to data length, means hidden layer number is good.\n",
    "sum(total_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f7960b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "57771b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percent = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a8a296f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training index\n",
    "train_ind = int(len(encoded_text) * train_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2f9ce98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = encoded_text[:train_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49e25d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = encoded_text[train_ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a6231020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f2c2517",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 60\n",
    "batch_size = 100\n",
    "\n",
    "seq_len = 100\n",
    "\n",
    "tracker = 0\n",
    "\n",
    "num_char = max(encoded_text)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "57614b2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cb/08ldvpl94c11nvsd53y91g_40000gn/T/ipykernel_14802/1919360790.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m         raise RuntimeError(\n\u001b[1;32m    161\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "if model.use_gpu:\n",
    "    model.cuda()\n",
    "    \n",
    "for i in range(epochs):\n",
    "    \n",
    "    hidden = model.hidden_state(batch_size)\n",
    "    \n",
    "    for x,y in generate_batches(train_data,batch_size,seq_len):\n",
    "        \n",
    "        tracker += 1\n",
    "        \n",
    "        x = one_hot_encoder(x, num_char)\n",
    "        \n",
    "        inputs = torch.from_numpy(x)\n",
    "        targets = torch.from_numpy(y)\n",
    "        \n",
    "        if model.use_gpu:\n",
    "            \n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            \n",
    "        hidden = tuple([state.data for state in hidden])\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        lstm_output,hidden = model.forward(inputs,hidden)\n",
    "        loss = criterion(lstm_output,targets.view(batch_size*seq_len).long())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(),max_norm=5)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if tracker % 25 == 0:\n",
    "            \n",
    "            val_hidden = model.hidden_state(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            \n",
    "            for x,y in generate_batches(val_data,batch_size,seq_len):\n",
    "                \n",
    "                x = one_hot_encoder(x, num_char)\n",
    "        \n",
    "                inputs = torch.from_numpy(x)\n",
    "                targets = torch.from_numpy(y)\n",
    "                \n",
    "                if model.use_gpu:\n",
    "                    \n",
    "                    inputs = inputs.cuda()\n",
    "                    targets = targets.cuda()\n",
    "                    \n",
    "                val_hidden = tuple([state.data for state in val_hidden])\n",
    "                \n",
    "                lstm_output,val_hidden = model.forward(inputs,val_hidden)\n",
    "                val_loss = criterion(lstm_output,targets.view(batch_size*seq_len).long())\n",
    "                \n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "            model.train()\n",
    "            \n",
    "            print(f\"EPOCH: {i} Step: {tracker} VAL LOSS: {val_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b5c195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed81dcd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
